// ignore_for_file: always_specify_types
// ignore_for_file: camel_case_types
// ignore_for_file: non_constant_identifier_names

// AUTO GENERATED FILE, DO NOT EDIT.
//
// Generated by `package:ffigen`.
// ignore_for_file: type=lint
import 'dart:ffi' as ffi;

/// Bindings for `zstd`.
///
/// Regenerate bindings with `dart run ffigen --config ffigen.yaml`.
///
class ZstdApi {
  /// Holds the symbol lookup function.
  final ffi.Pointer<T> Function<T extends ffi.NativeType>(String symbolName)
      _lookup;

  /// The symbols are looked up in [dynamicLibrary].
  ZstdApi(ffi.DynamicLibrary dynamicLibrary) : _lookup = dynamicLibrary.lookup;

  /// The symbols are looked up with [lookup].
  ZstdApi.fromLookup(
      ffi.Pointer<T> Function<T extends ffi.NativeType>(String symbolName)
          lookup)
      : _lookup = lookup;

  ffi.Pointer<ffi.Char> ZSTD_getErrorString(
    ZSTD_ErrorCode code,
  ) {
    return _ZSTD_getErrorString(
      code.value,
    );
  }

  late final _ZSTD_getErrorStringPtr = _lookup<
          ffi.NativeFunction<ffi.Pointer<ffi.Char> Function(ffi.UnsignedInt)>>(
      'ZSTD_getErrorString');
  late final _ZSTD_getErrorString =
      _ZSTD_getErrorStringPtr.asFunction<ffi.Pointer<ffi.Char> Function(int)>();

  /// ! ZSTD_versionNumber() :
  /// Return runtime library version, the value is (MAJOR*100*100 + MINOR*100 + RELEASE).
  int ZSTD_versionNumber() {
    return _ZSTD_versionNumber();
  }

  late final _ZSTD_versionNumberPtr =
      _lookup<ffi.NativeFunction<ffi.UnsignedInt Function()>>(
          'ZSTD_versionNumber');
  late final _ZSTD_versionNumber =
      _ZSTD_versionNumberPtr.asFunction<int Function()>();

  /// ! ZSTD_versionString() :
  /// Return runtime library version, like "1.4.5". Requires v1.3.0+.
  ffi.Pointer<ffi.Char> ZSTD_versionString() {
    return _ZSTD_versionString();
  }

  late final _ZSTD_versionStringPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Char> Function()>>(
          'ZSTD_versionString');
  late final _ZSTD_versionString =
      _ZSTD_versionStringPtr.asFunction<ffi.Pointer<ffi.Char> Function()>();

  /// Simple Core API
  /// /
  /// /*! ZSTD_compress() :
  /// Compresses `src` content as a single zstd compressed frame into already allocated `dst`.
  /// NOTE: Providing `dstCapacity >= ZSTD_compressBound(srcSize)` guarantees that zstd will have
  /// enough space to successfully compress the data.
  /// @return : compressed size written into `dst` (<= `dstCapacity),
  /// or an error code if it fails (which can be tested using ZSTD_isError()).
  int ZSTD_compress(
    ffi.Pointer<ffi.Void> dst,
    int dstCapacity,
    ffi.Pointer<ffi.Void> src,
    int srcSize,
    int compressionLevel,
  ) {
    return _ZSTD_compress(
      dst,
      dstCapacity,
      src,
      srcSize,
      compressionLevel,
    );
  }

  late final _ZSTD_compressPtr = _lookup<
      ffi.NativeFunction<
          ffi.Size Function(ffi.Pointer<ffi.Void>, ffi.Size,
              ffi.Pointer<ffi.Void>, ffi.Size, ffi.Int)>>('ZSTD_compress');
  late final _ZSTD_compress = _ZSTD_compressPtr.asFunction<
      int Function(
          ffi.Pointer<ffi.Void>, int, ffi.Pointer<ffi.Void>, int, int)>();

  /// ! ZSTD_decompress() :
  /// `compressedSize` : must be the _exact_ size of some number of compressed and/or skippable frames.
  /// Multiple compressed frames can be decompressed at once with this method.
  /// The result will be the concatenation of all decompressed frames, back to back.
  /// `dstCapacity` is an upper bound of originalSize to regenerate.
  /// First frame's decompressed size can be extracted using ZSTD_getFrameContentSize().
  /// If maximum upper bound isn't known, prefer using streaming mode to decompress data.
  /// @return : the number of bytes decompressed into `dst` (<= `dstCapacity`),
  /// or an errorCode if it fails (which can be tested using ZSTD_isError()).
  int ZSTD_decompress(
    ffi.Pointer<ffi.Void> dst,
    int dstCapacity,
    ffi.Pointer<ffi.Void> src,
    int compressedSize,
  ) {
    return _ZSTD_decompress(
      dst,
      dstCapacity,
      src,
      compressedSize,
    );
  }

  late final _ZSTD_decompressPtr = _lookup<
      ffi.NativeFunction<
          ffi.Size Function(ffi.Pointer<ffi.Void>, ffi.Size,
              ffi.Pointer<ffi.Void>, ffi.Size)>>('ZSTD_decompress');
  late final _ZSTD_decompress = _ZSTD_decompressPtr.asFunction<
      int Function(ffi.Pointer<ffi.Void>, int, ffi.Pointer<ffi.Void>, int)>();

  int ZSTD_getFrameContentSize(
    ffi.Pointer<ffi.Void> src,
    int srcSize,
  ) {
    return _ZSTD_getFrameContentSize(
      src,
      srcSize,
    );
  }

  late final _ZSTD_getFrameContentSizePtr = _lookup<
      ffi.NativeFunction<
          ffi.UnsignedLongLong Function(
              ffi.Pointer<ffi.Void>, ffi.Size)>>('ZSTD_getFrameContentSize');
  late final _ZSTD_getFrameContentSize = _ZSTD_getFrameContentSizePtr
      .asFunction<int Function(ffi.Pointer<ffi.Void>, int)>();

  /// ! ZSTD_getDecompressedSize() (obsolete):
  /// This function is now obsolete, in favor of ZSTD_getFrameContentSize().
  /// Both functions work the same way, but ZSTD_getDecompressedSize() blends
  /// "empty", "unknown" and "error" results to the same return value (0),
  /// while ZSTD_getFrameContentSize() gives them separate return values.
  /// @return : decompressed size of `src` frame content _if known and not empty_, 0 otherwise.
  int ZSTD_getDecompressedSize(
    ffi.Pointer<ffi.Void> src,
    int srcSize,
  ) {
    return _ZSTD_getDecompressedSize(
      src,
      srcSize,
    );
  }

  late final _ZSTD_getDecompressedSizePtr = _lookup<
      ffi.NativeFunction<
          ffi.UnsignedLongLong Function(
              ffi.Pointer<ffi.Void>, ffi.Size)>>('ZSTD_getDecompressedSize');
  late final _ZSTD_getDecompressedSize = _ZSTD_getDecompressedSizePtr
      .asFunction<int Function(ffi.Pointer<ffi.Void>, int)>();

  /// ! ZSTD_findFrameCompressedSize() : Requires v1.4.0+
  /// `src` should point to the start of a ZSTD frame or skippable frame.
  /// `srcSize` must be >= first frame size
  /// @return : the compressed size of the first frame starting at `src`,
  /// suitable to pass as `srcSize` to `ZSTD_decompress` or similar,
  /// or an error code if input is invalid
  /// Note 1: this method is called _find*() because it's not enough to read the header,
  /// it may have to scan through the frame's content, to reach its end.
  /// Note 2: this method also works with Skippable Frames. In which case,
  /// it returns the size of the complete skippable frame,
  /// which is always equal to its content size + 8 bytes for headers.
  int ZSTD_findFrameCompressedSize(
    ffi.Pointer<ffi.Void> src,
    int srcSize,
  ) {
    return _ZSTD_findFrameCompressedSize(
      src,
      srcSize,
    );
  }

  late final _ZSTD_findFrameCompressedSizePtr = _lookup<
          ffi
          .NativeFunction<ffi.Size Function(ffi.Pointer<ffi.Void>, ffi.Size)>>(
      'ZSTD_findFrameCompressedSize');
  late final _ZSTD_findFrameCompressedSize = _ZSTD_findFrameCompressedSizePtr
      .asFunction<int Function(ffi.Pointer<ffi.Void>, int)>();

  int ZSTD_compressBound(
    int srcSize,
  ) {
    return _ZSTD_compressBound(
      srcSize,
    );
  }

  late final _ZSTD_compressBoundPtr =
      _lookup<ffi.NativeFunction<ffi.Size Function(ffi.Size)>>(
          'ZSTD_compressBound');
  late final _ZSTD_compressBound =
      _ZSTD_compressBoundPtr.asFunction<int Function(int)>();

  /// ======  Error helper functions  ======*/
  /// /* ZSTD_isError() :
  /// Most ZSTD_* functions returning a size_t value can be tested for error,
  /// using ZSTD_isError().
  /// @return 1 if error, 0 otherwise
  int ZSTD_isError(
    int result,
  ) {
    return _ZSTD_isError(
      result,
    );
  }

  late final _ZSTD_isErrorPtr =
      _lookup<ffi.NativeFunction<ffi.UnsignedInt Function(ffi.Size)>>(
          'ZSTD_isError');
  late final _ZSTD_isError = _ZSTD_isErrorPtr.asFunction<int Function(int)>();

  ZSTD_ErrorCode ZSTD_getErrorCode(
    int functionResult,
  ) {
    return ZSTD_ErrorCode.fromValue(_ZSTD_getErrorCode(
      functionResult,
    ));
  }

  late final _ZSTD_getErrorCodePtr =
      _lookup<ffi.NativeFunction<ffi.UnsignedInt Function(ffi.Size)>>(
          'ZSTD_getErrorCode');
  late final _ZSTD_getErrorCode =
      _ZSTD_getErrorCodePtr.asFunction<int Function(int)>();

  ffi.Pointer<ffi.Char> ZSTD_getErrorName(
    int result,
  ) {
    return _ZSTD_getErrorName(
      result,
    );
  }

  late final _ZSTD_getErrorNamePtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Char> Function(ffi.Size)>>(
          'ZSTD_getErrorName');
  late final _ZSTD_getErrorName =
      _ZSTD_getErrorNamePtr.asFunction<ffi.Pointer<ffi.Char> Function(int)>();

  int ZSTD_minCLevel() {
    return _ZSTD_minCLevel();
  }

  late final _ZSTD_minCLevelPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('ZSTD_minCLevel');
  late final _ZSTD_minCLevel = _ZSTD_minCLevelPtr.asFunction<int Function()>();

  int ZSTD_maxCLevel() {
    return _ZSTD_maxCLevel();
  }

  late final _ZSTD_maxCLevelPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('ZSTD_maxCLevel');
  late final _ZSTD_maxCLevel = _ZSTD_maxCLevelPtr.asFunction<int Function()>();

  int ZSTD_defaultCLevel() {
    return _ZSTD_defaultCLevel();
  }

  late final _ZSTD_defaultCLevelPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('ZSTD_defaultCLevel');
  late final _ZSTD_defaultCLevel =
      _ZSTD_defaultCLevelPtr.asFunction<int Function()>();

  ffi.Pointer<ZSTD_CCtx> ZSTD_createCCtx() {
    return _ZSTD_createCCtx();
  }

  late final _ZSTD_createCCtxPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ZSTD_CCtx> Function()>>(
          'ZSTD_createCCtx');
  late final _ZSTD_createCCtx =
      _ZSTD_createCCtxPtr.asFunction<ffi.Pointer<ZSTD_CCtx> Function()>();

  int ZSTD_freeCCtx(
    ffi.Pointer<ZSTD_CCtx> cctx,
  ) {
    return _ZSTD_freeCCtx(
      cctx,
    );
  }

  late final _ZSTD_freeCCtxPtr =
      _lookup<ffi.NativeFunction<ffi.Size Function(ffi.Pointer<ZSTD_CCtx>)>>(
          'ZSTD_freeCCtx');
  late final _ZSTD_freeCCtx =
      _ZSTD_freeCCtxPtr.asFunction<int Function(ffi.Pointer<ZSTD_CCtx>)>();

  /// ! ZSTD_compressCCtx() :
  /// Same as ZSTD_compress(), using an explicit ZSTD_CCtx.
  /// Important : in order to mirror `ZSTD_compress()` behavior,
  /// this function compresses at the requested compression level,
  /// __ignoring any other advanced parameter__ .
  /// If any advanced parameter was set using the advanced API,
  /// they will all be reset. Only @compressionLevel remains.
  int ZSTD_compressCCtx(
    ffi.Pointer<ZSTD_CCtx> cctx,
    ffi.Pointer<ffi.Void> dst,
    int dstCapacity,
    ffi.Pointer<ffi.Void> src,
    int srcSize,
    int compressionLevel,
  ) {
    return _ZSTD_compressCCtx(
      cctx,
      dst,
      dstCapacity,
      src,
      srcSize,
      compressionLevel,
    );
  }

  late final _ZSTD_compressCCtxPtr = _lookup<
      ffi.NativeFunction<
          ffi.Size Function(
              ffi.Pointer<ZSTD_CCtx>,
              ffi.Pointer<ffi.Void>,
              ffi.Size,
              ffi.Pointer<ffi.Void>,
              ffi.Size,
              ffi.Int)>>('ZSTD_compressCCtx');
  late final _ZSTD_compressCCtx = _ZSTD_compressCCtxPtr.asFunction<
      int Function(ffi.Pointer<ZSTD_CCtx>, ffi.Pointer<ffi.Void>, int,
          ffi.Pointer<ffi.Void>, int, int)>();

  ffi.Pointer<ZSTD_DCtx> ZSTD_createDCtx() {
    return _ZSTD_createDCtx();
  }

  late final _ZSTD_createDCtxPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ZSTD_DCtx> Function()>>(
          'ZSTD_createDCtx');
  late final _ZSTD_createDCtx =
      _ZSTD_createDCtxPtr.asFunction<ffi.Pointer<ZSTD_DCtx> Function()>();

  int ZSTD_freeDCtx(
    ffi.Pointer<ZSTD_DCtx> dctx,
  ) {
    return _ZSTD_freeDCtx(
      dctx,
    );
  }

  late final _ZSTD_freeDCtxPtr =
      _lookup<ffi.NativeFunction<ffi.Size Function(ffi.Pointer<ZSTD_DCtx>)>>(
          'ZSTD_freeDCtx');
  late final _ZSTD_freeDCtx =
      _ZSTD_freeDCtxPtr.asFunction<int Function(ffi.Pointer<ZSTD_DCtx>)>();

  /// ! ZSTD_decompressDCtx() :
  /// Same as ZSTD_decompress(),
  /// requires an allocated ZSTD_DCtx.
  /// Compatible with sticky parameters (see below).
  int ZSTD_decompressDCtx(
    ffi.Pointer<ZSTD_DCtx> dctx,
    ffi.Pointer<ffi.Void> dst,
    int dstCapacity,
    ffi.Pointer<ffi.Void> src,
    int srcSize,
  ) {
    return _ZSTD_decompressDCtx(
      dctx,
      dst,
      dstCapacity,
      src,
      srcSize,
    );
  }

  late final _ZSTD_decompressDCtxPtr = _lookup<
      ffi.NativeFunction<
          ffi.Size Function(
              ffi.Pointer<ZSTD_DCtx>,
              ffi.Pointer<ffi.Void>,
              ffi.Size,
              ffi.Pointer<ffi.Void>,
              ffi.Size)>>('ZSTD_decompressDCtx');
  late final _ZSTD_decompressDCtx = _ZSTD_decompressDCtxPtr.asFunction<
      int Function(ffi.Pointer<ZSTD_DCtx>, ffi.Pointer<ffi.Void>, int,
          ffi.Pointer<ffi.Void>, int)>();

  /// ! ZSTD_cParam_getBounds() :
  /// All parameters must belong to an interval with lower and upper bounds,
  /// otherwise they will either trigger an error or be automatically clamped.
  /// @return : a structure, ZSTD_bounds, which contains
  /// - an error status field, which must be tested using ZSTD_isError()
  /// - lower and upper bounds, both inclusive
  ZSTD_bounds ZSTD_cParam_getBounds(
    ZSTD_cParameter cParam,
  ) {
    return _ZSTD_cParam_getBounds(
      cParam.value,
    );
  }

  late final _ZSTD_cParam_getBoundsPtr =
      _lookup<ffi.NativeFunction<ZSTD_bounds Function(ffi.UnsignedInt)>>(
          'ZSTD_cParam_getBounds');
  late final _ZSTD_cParam_getBounds =
      _ZSTD_cParam_getBoundsPtr.asFunction<ZSTD_bounds Function(int)>();

  /// ! ZSTD_CCtx_setParameter() :
  /// Set one compression parameter, selected by enum ZSTD_cParameter.
  /// All parameters have valid bounds. Bounds can be queried using ZSTD_cParam_getBounds().
  /// Providing a value beyond bound will either clamp it, or trigger an error (depending on parameter).
  /// Setting a parameter is generally only possible during frame initialization (before starting compression).
  /// Exception : when using multi-threading mode (nbWorkers >= 1),
  /// the following parameters can be updated _during_ compression (within same frame):
  /// => compressionLevel, hashLog, chainLog, searchLog, minMatch, targetLength and strategy.
  /// new parameters will be active for next job only (after a flush()).
  /// @return : an error code (which can be tested using ZSTD_isError()).
  int ZSTD_CCtx_setParameter(
    ffi.Pointer<ZSTD_CCtx> cctx,
    ZSTD_cParameter param,
    int value,
  ) {
    return _ZSTD_CCtx_setParameter(
      cctx,
      param.value,
      value,
    );
  }

  late final _ZSTD_CCtx_setParameterPtr = _lookup<
      ffi.NativeFunction<
          ffi.Size Function(ffi.Pointer<ZSTD_CCtx>, ffi.UnsignedInt,
              ffi.Int)>>('ZSTD_CCtx_setParameter');
  late final _ZSTD_CCtx_setParameter = _ZSTD_CCtx_setParameterPtr.asFunction<
      int Function(ffi.Pointer<ZSTD_CCtx>, int, int)>();

  /// ! ZSTD_CCtx_setPledgedSrcSize() :
  /// Total input data size to be compressed as a single frame.
  /// Value will be written in frame header, unless if explicitly forbidden using ZSTD_c_contentSizeFlag.
  /// This value will also be controlled at end of frame, and trigger an error if not respected.
  /// @result : 0, or an error code (which can be tested with ZSTD_isError()).
  /// Note 1 : pledgedSrcSize==0 actually means zero, aka an empty frame.
  /// In order to mean "unknown content size", pass constant ZSTD_CONTENTSIZE_UNKNOWN.
  /// ZSTD_CONTENTSIZE_UNKNOWN is default value for any new frame.
  /// Note 2 : pledgedSrcSize is only valid once, for the next frame.
  /// It's discarded at the end of the frame, and replaced by ZSTD_CONTENTSIZE_UNKNOWN.
  /// Note 3 : Whenever all input data is provided and consumed in a single round,
  /// for example with ZSTD_compress2(),
  /// or invoking immediately ZSTD_compressStream2(,,,ZSTD_e_end),
  /// this value is automatically overridden by srcSize instead.
  int ZSTD_CCtx_setPledgedSrcSize(
    ffi.Pointer<ZSTD_CCtx> cctx,
    int pledgedSrcSize,
  ) {
    return _ZSTD_CCtx_setPledgedSrcSize(
      cctx,
      pledgedSrcSize,
    );
  }

  late final _ZSTD_CCtx_setPledgedSrcSizePtr = _lookup<
      ffi.NativeFunction<
          ffi.Size Function(ffi.Pointer<ZSTD_CCtx>,
              ffi.UnsignedLongLong)>>('ZSTD_CCtx_setPledgedSrcSize');
  late final _ZSTD_CCtx_setPledgedSrcSize = _ZSTD_CCtx_setPledgedSrcSizePtr
      .asFunction<int Function(ffi.Pointer<ZSTD_CCtx>, int)>();

  /// ! ZSTD_CCtx_reset() :
  /// There are 2 different things that can be reset, independently or jointly :
  /// - The session : will stop compressing current frame, and make CCtx ready to start a new one.
  /// Useful after an error, or to interrupt any ongoing compression.
  /// Any internal data not yet flushed is cancelled.
  /// Compression parameters and dictionary remain unchanged.
  /// They will be used to compress next frame.
  /// Resetting session never fails.
  /// - The parameters : changes all parameters back to "default".
  /// This also removes any reference to any dictionary or external sequence producer.
  /// Parameters can only be changed between 2 sessions (i.e. no compression is currently ongoing)
  /// otherwise the reset fails, and function returns an error value (which can be tested using ZSTD_isError())
  /// - Both : similar to resetting the session, followed by resetting parameters.
  int ZSTD_CCtx_reset(
    ffi.Pointer<ZSTD_CCtx> cctx,
    ZSTD_ResetDirective reset,
  ) {
    return _ZSTD_CCtx_reset(
      cctx,
      reset.value,
    );
  }

  late final _ZSTD_CCtx_resetPtr = _lookup<
      ffi.NativeFunction<
          ffi.Size Function(
              ffi.Pointer<ZSTD_CCtx>, ffi.UnsignedInt)>>('ZSTD_CCtx_reset');
  late final _ZSTD_CCtx_reset = _ZSTD_CCtx_resetPtr.asFunction<
      int Function(ffi.Pointer<ZSTD_CCtx>, int)>();

  /// ! ZSTD_compress2() :
  /// Behave the same as ZSTD_compressCCtx(), but compression parameters are set using the advanced API.
  /// (note that this entry point doesn't even expose a compression level parameter).
  /// ZSTD_compress2() always starts a new frame.
  /// Should cctx hold data from a previously unfinished frame, everything about it is forgotten.
  /// - Compression parameters are pushed into CCtx before starting compression, using ZSTD_CCtx_set*()
  /// - The function is always blocking, returns when compression is completed.
  /// NOTE: Providing `dstCapacity >= ZSTD_compressBound(srcSize)` guarantees that zstd will have
  /// enough space to successfully compress the data, though it is possible it fails for other reasons.
  /// @return : compressed size written into `dst` (<= `dstCapacity),
  /// or an error code if it fails (which can be tested using ZSTD_isError()).
  int ZSTD_compress2(
    ffi.Pointer<ZSTD_CCtx> cctx,
    ffi.Pointer<ffi.Void> dst,
    int dstCapacity,
    ffi.Pointer<ffi.Void> src,
    int srcSize,
  ) {
    return _ZSTD_compress2(
      cctx,
      dst,
      dstCapacity,
      src,
      srcSize,
    );
  }

  late final _ZSTD_compress2Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Size Function(ffi.Pointer<ZSTD_CCtx>, ffi.Pointer<ffi.Void>,
              ffi.Size, ffi.Pointer<ffi.Void>, ffi.Size)>>('ZSTD_compress2');
  late final _ZSTD_compress2 = _ZSTD_compress2Ptr.asFunction<
      int Function(ffi.Pointer<ZSTD_CCtx>, ffi.Pointer<ffi.Void>, int,
          ffi.Pointer<ffi.Void>, int)>();

  /// ! ZSTD_dParam_getBounds() :
  /// All parameters must belong to an interval with lower and upper bounds,
  /// otherwise they will either trigger an error or be automatically clamped.
  /// @return : a structure, ZSTD_bounds, which contains
  /// - an error status field, which must be tested using ZSTD_isError()
  /// - both lower and upper bounds, inclusive
  ZSTD_bounds ZSTD_dParam_getBounds(
    ZSTD_dParameter dParam,
  ) {
    return _ZSTD_dParam_getBounds(
      dParam.value,
    );
  }

  late final _ZSTD_dParam_getBoundsPtr =
      _lookup<ffi.NativeFunction<ZSTD_bounds Function(ffi.UnsignedInt)>>(
          'ZSTD_dParam_getBounds');
  late final _ZSTD_dParam_getBounds =
      _ZSTD_dParam_getBoundsPtr.asFunction<ZSTD_bounds Function(int)>();

  /// ! ZSTD_DCtx_setParameter() :
  /// Set one compression parameter, selected by enum ZSTD_dParameter.
  /// All parameters have valid bounds. Bounds can be queried using ZSTD_dParam_getBounds().
  /// Providing a value beyond bound will either clamp it, or trigger an error (depending on parameter).
  /// Setting a parameter is only possible during frame initialization (before starting decompression).
  /// @return : 0, or an error code (which can be tested using ZSTD_isError()).
  int ZSTD_DCtx_setParameter(
    ffi.Pointer<ZSTD_DCtx> dctx,
    ZSTD_dParameter param,
    int value,
  ) {
    return _ZSTD_DCtx_setParameter(
      dctx,
      param.value,
      value,
    );
  }

  late final _ZSTD_DCtx_setParameterPtr = _lookup<
      ffi.NativeFunction<
          ffi.Size Function(ffi.Pointer<ZSTD_DCtx>, ffi.UnsignedInt,
              ffi.Int)>>('ZSTD_DCtx_setParameter');
  late final _ZSTD_DCtx_setParameter = _ZSTD_DCtx_setParameterPtr.asFunction<
      int Function(ffi.Pointer<ZSTD_DCtx>, int, int)>();

  /// ! ZSTD_DCtx_reset() :
  /// Return a DCtx to clean state.
  /// Session and parameters can be reset jointly or separately.
  /// Parameters can only be reset when no active frame is being decompressed.
  /// @return : 0, or an error code, which can be tested with ZSTD_isError()
  int ZSTD_DCtx_reset(
    ffi.Pointer<ZSTD_DCtx> dctx,
    ZSTD_ResetDirective reset,
  ) {
    return _ZSTD_DCtx_reset(
      dctx,
      reset.value,
    );
  }

  late final _ZSTD_DCtx_resetPtr = _lookup<
      ffi.NativeFunction<
          ffi.Size Function(
              ffi.Pointer<ZSTD_DCtx>, ffi.UnsignedInt)>>('ZSTD_DCtx_reset');
  late final _ZSTD_DCtx_reset = _ZSTD_DCtx_resetPtr.asFunction<
      int Function(ffi.Pointer<ZSTD_DCtx>, int)>();

  /// ===== ZSTD_CStream management functions =====
  ffi.Pointer<ZSTD_CStream> ZSTD_createCStream() {
    return _ZSTD_createCStream();
  }

  late final _ZSTD_createCStreamPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ZSTD_CStream> Function()>>(
          'ZSTD_createCStream');
  late final _ZSTD_createCStream =
      _ZSTD_createCStreamPtr.asFunction<ffi.Pointer<ZSTD_CStream> Function()>();

  int ZSTD_freeCStream(
    ffi.Pointer<ZSTD_CStream> zcs,
  ) {
    return _ZSTD_freeCStream(
      zcs,
    );
  }

  late final _ZSTD_freeCStreamPtr =
      _lookup<ffi.NativeFunction<ffi.Size Function(ffi.Pointer<ZSTD_CStream>)>>(
          'ZSTD_freeCStream');
  late final _ZSTD_freeCStream = _ZSTD_freeCStreamPtr.asFunction<
      int Function(ffi.Pointer<ZSTD_CStream>)>();

  /// ! ZSTD_compressStream2() : Requires v1.4.0+
  /// Behaves about the same as ZSTD_compressStream, with additional control on end directive.
  /// - Compression parameters are pushed into CCtx before starting compression, using ZSTD_CCtx_set*()
  /// - Compression parameters cannot be changed once compression is started (save a list of exceptions in multi-threading mode)
  /// - output->pos must be <= dstCapacity, input->pos must be <= srcSize
  /// - output->pos and input->pos will be updated. They are guaranteed to remain below their respective limit.
  /// - endOp must be a valid directive
  /// - When nbWorkers==0 (default), function is blocking : it completes its job before returning to caller.
  /// - When nbWorkers>=1, function is non-blocking : it copies a portion of input, distributes jobs to internal worker threads, flush to output whatever is available,
  /// and then immediately returns, just indicating that there is some data remaining to be flushed.
  /// The function nonetheless guarantees forward progress : it will return only after it reads or write at least 1+ byte.
  /// - Exception : if the first call requests a ZSTD_e_end directive and provides enough dstCapacity, the function delegates to ZSTD_compress2() which is always blocking.
  /// - @return provides a minimum amount of data remaining to be flushed from internal buffers
  /// or an error code, which can be tested using ZSTD_isError().
  /// if @return != 0, flush is not fully completed, there is still some data left within internal buffers.
  /// This is useful for ZSTD_e_flush, since in this case more flushes are necessary to empty all buffers.
  /// For ZSTD_e_end, @return == 0 when internal buffers are fully flushed and frame is completed.
  /// - after a ZSTD_e_end directive, if internal buffer is not fully flushed (@return != 0),
  /// only ZSTD_e_end or ZSTD_e_flush operations are allowed.
  /// Before starting a new compression job, or changing compression parameters,
  /// it is required to fully flush internal buffers.
  /// - note: if an operation ends with an error, it may leave @cctx in an undefined state.
  /// Therefore, it's UB to invoke ZSTD_compressStream2() of ZSTD_compressStream() on such a state.
  /// In order to be re-employed after an error, a state must be reset,
  /// which can be done explicitly (ZSTD_CCtx_reset()),
  /// or is sometimes implied by methods starting a new compression job (ZSTD_initCStream(), ZSTD_compressCCtx())
  int ZSTD_compressStream2(
    ffi.Pointer<ZSTD_CCtx> cctx,
    ffi.Pointer<ZSTD_outBuffer> output,
    ffi.Pointer<ZSTD_inBuffer> input,
    ZSTD_EndDirective endOp,
  ) {
    return _ZSTD_compressStream2(
      cctx,
      output,
      input,
      endOp.value,
    );
  }

  late final _ZSTD_compressStream2Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Size Function(
              ffi.Pointer<ZSTD_CCtx>,
              ffi.Pointer<ZSTD_outBuffer>,
              ffi.Pointer<ZSTD_inBuffer>,
              ffi.UnsignedInt)>>('ZSTD_compressStream2');
  late final _ZSTD_compressStream2 = _ZSTD_compressStream2Ptr.asFunction<
      int Function(ffi.Pointer<ZSTD_CCtx>, ffi.Pointer<ZSTD_outBuffer>,
          ffi.Pointer<ZSTD_inBuffer>, int)>();

  /// These buffer sizes are softly recommended.
  /// They are not required : ZSTD_compressStream*() happily accepts any buffer size, for both input and output.
  /// Respecting the recommended size just makes it a bit easier for ZSTD_compressStream*(),
  /// reducing the amount of memory shuffling and buffering, resulting in minor performance savings.
  ///
  /// However, note that these recommendations are from the perspective of a C caller program.
  /// If the streaming interface is invoked from some other language,
  /// especially managed ones such as Java or Go, through a foreign function interface such as jni or cgo,
  /// a major performance rule is to reduce crossing such interface to an absolute minimum.
  /// It's not rare that performance ends being spent more into the interface, rather than compression itself.
  /// In which cases, prefer using large buffers, as large as practical,
  /// for both input and output, to reduce the nb of roundtrips.
  int ZSTD_CStreamInSize() {
    return _ZSTD_CStreamInSize();
  }

  late final _ZSTD_CStreamInSizePtr =
      _lookup<ffi.NativeFunction<ffi.Size Function()>>('ZSTD_CStreamInSize');
  late final _ZSTD_CStreamInSize =
      _ZSTD_CStreamInSizePtr.asFunction<int Function()>();

  int ZSTD_CStreamOutSize() {
    return _ZSTD_CStreamOutSize();
  }

  late final _ZSTD_CStreamOutSizePtr =
      _lookup<ffi.NativeFunction<ffi.Size Function()>>('ZSTD_CStreamOutSize');
  late final _ZSTD_CStreamOutSize =
      _ZSTD_CStreamOutSizePtr.asFunction<int Function()>();

  /// !
  /// Equivalent to:
  ///
  /// ZSTD_CCtx_reset(zcs, ZSTD_reset_session_only);
  /// ZSTD_CCtx_refCDict(zcs, NULL); // clear the dictionary (if any)
  /// ZSTD_CCtx_setParameter(zcs, ZSTD_c_compressionLevel, compressionLevel);
  ///
  /// Note that ZSTD_initCStream() clears any previously set dictionary. Use the new API
  /// to compress with a dictionary.
  int ZSTD_initCStream(
    ffi.Pointer<ZSTD_CStream> zcs,
    int compressionLevel,
  ) {
    return _ZSTD_initCStream(
      zcs,
      compressionLevel,
    );
  }

  late final _ZSTD_initCStreamPtr = _lookup<
      ffi.NativeFunction<
          ffi.Size Function(
              ffi.Pointer<ZSTD_CStream>, ffi.Int)>>('ZSTD_initCStream');
  late final _ZSTD_initCStream = _ZSTD_initCStreamPtr.asFunction<
      int Function(ffi.Pointer<ZSTD_CStream>, int)>();

  /// !
  /// Alternative for ZSTD_compressStream2(zcs, output, input, ZSTD_e_continue).
  /// NOTE: The return value is different. ZSTD_compressStream() returns a hint for
  /// the next read size (if non-zero and not an error). ZSTD_compressStream2()
  /// returns the minimum nb of bytes left to flush (if non-zero and not an error).
  int ZSTD_compressStream(
    ffi.Pointer<ZSTD_CStream> zcs,
    ffi.Pointer<ZSTD_outBuffer> output,
    ffi.Pointer<ZSTD_inBuffer> input,
  ) {
    return _ZSTD_compressStream(
      zcs,
      output,
      input,
    );
  }

  late final _ZSTD_compressStreamPtr = _lookup<
      ffi.NativeFunction<
          ffi.Size Function(
              ffi.Pointer<ZSTD_CStream>,
              ffi.Pointer<ZSTD_outBuffer>,
              ffi.Pointer<ZSTD_inBuffer>)>>('ZSTD_compressStream');
  late final _ZSTD_compressStream = _ZSTD_compressStreamPtr.asFunction<
      int Function(ffi.Pointer<ZSTD_CStream>, ffi.Pointer<ZSTD_outBuffer>,
          ffi.Pointer<ZSTD_inBuffer>)>();

  /// ! Equivalent to ZSTD_compressStream2(zcs, output, &emptyInput, ZSTD_e_flush).
  int ZSTD_flushStream(
    ffi.Pointer<ZSTD_CStream> zcs,
    ffi.Pointer<ZSTD_outBuffer> output,
  ) {
    return _ZSTD_flushStream(
      zcs,
      output,
    );
  }

  late final _ZSTD_flushStreamPtr = _lookup<
      ffi.NativeFunction<
          ffi.Size Function(ffi.Pointer<ZSTD_CStream>,
              ffi.Pointer<ZSTD_outBuffer>)>>('ZSTD_flushStream');
  late final _ZSTD_flushStream = _ZSTD_flushStreamPtr.asFunction<
      int Function(ffi.Pointer<ZSTD_CStream>, ffi.Pointer<ZSTD_outBuffer>)>();

  /// ! Equivalent to ZSTD_compressStream2(zcs, output, &emptyInput, ZSTD_e_end).
  int ZSTD_endStream(
    ffi.Pointer<ZSTD_CStream> zcs,
    ffi.Pointer<ZSTD_outBuffer> output,
  ) {
    return _ZSTD_endStream(
      zcs,
      output,
    );
  }

  late final _ZSTD_endStreamPtr = _lookup<
      ffi.NativeFunction<
          ffi.Size Function(ffi.Pointer<ZSTD_CStream>,
              ffi.Pointer<ZSTD_outBuffer>)>>('ZSTD_endStream');
  late final _ZSTD_endStream = _ZSTD_endStreamPtr.asFunction<
      int Function(ffi.Pointer<ZSTD_CStream>, ffi.Pointer<ZSTD_outBuffer>)>();

  /// ===== ZSTD_DStream management functions =====
  ffi.Pointer<ZSTD_DStream> ZSTD_createDStream() {
    return _ZSTD_createDStream();
  }

  late final _ZSTD_createDStreamPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ZSTD_DStream> Function()>>(
          'ZSTD_createDStream');
  late final _ZSTD_createDStream =
      _ZSTD_createDStreamPtr.asFunction<ffi.Pointer<ZSTD_DStream> Function()>();

  int ZSTD_freeDStream(
    ffi.Pointer<ZSTD_DStream> zds,
  ) {
    return _ZSTD_freeDStream(
      zds,
    );
  }

  late final _ZSTD_freeDStreamPtr =
      _lookup<ffi.NativeFunction<ffi.Size Function(ffi.Pointer<ZSTD_DStream>)>>(
          'ZSTD_freeDStream');
  late final _ZSTD_freeDStream = _ZSTD_freeDStreamPtr.asFunction<
      int Function(ffi.Pointer<ZSTD_DStream>)>();

  /// ! ZSTD_initDStream() :
  /// Initialize/reset DStream state for new decompression operation.
  /// Call before new decompression operation using same DStream.
  ///
  /// Note : This function is redundant with the advanced API and equivalent to:
  /// ZSTD_DCtx_reset(zds, ZSTD_reset_session_only);
  /// ZSTD_DCtx_refDDict(zds, NULL);
  int ZSTD_initDStream(
    ffi.Pointer<ZSTD_DStream> zds,
  ) {
    return _ZSTD_initDStream(
      zds,
    );
  }

  late final _ZSTD_initDStreamPtr =
      _lookup<ffi.NativeFunction<ffi.Size Function(ffi.Pointer<ZSTD_DStream>)>>(
          'ZSTD_initDStream');
  late final _ZSTD_initDStream = _ZSTD_initDStreamPtr.asFunction<
      int Function(ffi.Pointer<ZSTD_DStream>)>();

  /// ! ZSTD_decompressStream() :
  /// Streaming decompression function.
  /// Call repetitively to consume full input updating it as necessary.
  /// Function will update both input and output `pos` fields exposing current state via these fields:
  /// - `input.pos < input.size`, some input remaining and caller should provide remaining input
  /// on the next call.
  /// - `output.pos < output.size`, decoder flushed internal output buffer.
  /// - `output.pos == output.size`, unflushed data potentially present in the internal buffers,
  /// check ZSTD_decompressStream() @return value,
  /// if > 0, invoke it again to flush remaining data to output.
  /// Note : with no additional input, amount of data flushed <= ZSTD_BLOCKSIZE_MAX.
  ///
  /// @return : 0 when a frame is completely decoded and fully flushed,
  /// or an error code, which can be tested using ZSTD_isError(),
  /// or any other value > 0, which means there is some decoding or flushing to do to complete current frame.
  ///
  /// Note: when an operation returns with an error code, the @zds state may be left in undefined state.
  /// It's UB to invoke `ZSTD_decompressStream()` on such a state.
  /// In order to re-use such a state, it must be first reset,
  /// which can be done explicitly (`ZSTD_DCtx_reset()`),
  /// or is implied for operations starting some new decompression job (`ZSTD_initDStream`, `ZSTD_decompressDCtx()`, `ZSTD_decompress_usingDict()`)
  int ZSTD_decompressStream(
    ffi.Pointer<ZSTD_DStream> zds,
    ffi.Pointer<ZSTD_outBuffer> output,
    ffi.Pointer<ZSTD_inBuffer> input,
  ) {
    return _ZSTD_decompressStream(
      zds,
      output,
      input,
    );
  }

  late final _ZSTD_decompressStreamPtr = _lookup<
      ffi.NativeFunction<
          ffi.Size Function(
              ffi.Pointer<ZSTD_DStream>,
              ffi.Pointer<ZSTD_outBuffer>,
              ffi.Pointer<ZSTD_inBuffer>)>>('ZSTD_decompressStream');
  late final _ZSTD_decompressStream = _ZSTD_decompressStreamPtr.asFunction<
      int Function(ffi.Pointer<ZSTD_DStream>, ffi.Pointer<ZSTD_outBuffer>,
          ffi.Pointer<ZSTD_inBuffer>)>();

  int ZSTD_DStreamInSize() {
    return _ZSTD_DStreamInSize();
  }

  late final _ZSTD_DStreamInSizePtr =
      _lookup<ffi.NativeFunction<ffi.Size Function()>>('ZSTD_DStreamInSize');
  late final _ZSTD_DStreamInSize =
      _ZSTD_DStreamInSizePtr.asFunction<int Function()>();

  int ZSTD_DStreamOutSize() {
    return _ZSTD_DStreamOutSize();
  }

  late final _ZSTD_DStreamOutSizePtr =
      _lookup<ffi.NativeFunction<ffi.Size Function()>>('ZSTD_DStreamOutSize');
  late final _ZSTD_DStreamOutSize =
      _ZSTD_DStreamOutSizePtr.asFunction<int Function()>();

  /// Simple dictionary API
  /// /
  /// /*! ZSTD_compress_usingDict() :
  /// Compression at an explicit compression level using a Dictionary.
  /// A dictionary can be any arbitrary data segment (also called a prefix),
  /// or a buffer with specified information (see zdict.h).
  /// Note : This function loads the dictionary, resulting in significant startup delay.
  /// It's intended for a dictionary used only once.
  /// Note 2 : When `dict == NULL || dictSize < 8` no dictionary is used.
  int ZSTD_compress_usingDict(
    ffi.Pointer<ZSTD_CCtx> ctx,
    ffi.Pointer<ffi.Void> dst,
    int dstCapacity,
    ffi.Pointer<ffi.Void> src,
    int srcSize,
    ffi.Pointer<ffi.Void> dict,
    int dictSize,
    int compressionLevel,
  ) {
    return _ZSTD_compress_usingDict(
      ctx,
      dst,
      dstCapacity,
      src,
      srcSize,
      dict,
      dictSize,
      compressionLevel,
    );
  }

  late final _ZSTD_compress_usingDictPtr = _lookup<
      ffi.NativeFunction<
          ffi.Size Function(
              ffi.Pointer<ZSTD_CCtx>,
              ffi.Pointer<ffi.Void>,
              ffi.Size,
              ffi.Pointer<ffi.Void>,
              ffi.Size,
              ffi.Pointer<ffi.Void>,
              ffi.Size,
              ffi.Int)>>('ZSTD_compress_usingDict');
  late final _ZSTD_compress_usingDict = _ZSTD_compress_usingDictPtr.asFunction<
      int Function(ffi.Pointer<ZSTD_CCtx>, ffi.Pointer<ffi.Void>, int,
          ffi.Pointer<ffi.Void>, int, ffi.Pointer<ffi.Void>, int, int)>();

  /// ! ZSTD_decompress_usingDict() :
  /// Decompression using a known Dictionary.
  /// Dictionary must be identical to the one used during compression.
  /// Note : This function loads the dictionary, resulting in significant startup delay.
  /// It's intended for a dictionary used only once.
  /// Note : When `dict == NULL || dictSize < 8` no dictionary is used.
  int ZSTD_decompress_usingDict(
    ffi.Pointer<ZSTD_DCtx> dctx,
    ffi.Pointer<ffi.Void> dst,
    int dstCapacity,
    ffi.Pointer<ffi.Void> src,
    int srcSize,
    ffi.Pointer<ffi.Void> dict,
    int dictSize,
  ) {
    return _ZSTD_decompress_usingDict(
      dctx,
      dst,
      dstCapacity,
      src,
      srcSize,
      dict,
      dictSize,
    );
  }

  late final _ZSTD_decompress_usingDictPtr = _lookup<
      ffi.NativeFunction<
          ffi.Size Function(
              ffi.Pointer<ZSTD_DCtx>,
              ffi.Pointer<ffi.Void>,
              ffi.Size,
              ffi.Pointer<ffi.Void>,
              ffi.Size,
              ffi.Pointer<ffi.Void>,
              ffi.Size)>>('ZSTD_decompress_usingDict');
  late final _ZSTD_decompress_usingDict =
      _ZSTD_decompress_usingDictPtr.asFunction<
          int Function(ffi.Pointer<ZSTD_DCtx>, ffi.Pointer<ffi.Void>, int,
              ffi.Pointer<ffi.Void>, int, ffi.Pointer<ffi.Void>, int)>();

  /// ! ZSTD_createCDict() :
  /// When compressing multiple messages or blocks using the same dictionary,
  /// it's recommended to digest the dictionary only once, since it's a costly operation.
  /// ZSTD_createCDict() will create a state from digesting a dictionary.
  /// The resulting state can be used for future compression operations with very limited startup cost.
  /// ZSTD_CDict can be created once and shared by multiple threads concurrently, since its usage is read-only.
  /// @dictBuffer can be released after ZSTD_CDict creation, because its content is copied within CDict.
  /// Note 1 : Consider experimental function `ZSTD_createCDict_byReference()` if you prefer to not duplicate @dictBuffer content.
  /// Note 2 : A ZSTD_CDict can be created from an empty @dictBuffer,
  /// in which case the only thing that it transports is the @compressionLevel.
  /// This can be useful in a pipeline featuring ZSTD_compress_usingCDict() exclusively,
  /// expecting a ZSTD_CDict parameter with any data, including those without a known dictionary.
  ffi.Pointer<ZSTD_CDict> ZSTD_createCDict(
    ffi.Pointer<ffi.Void> dictBuffer,
    int dictSize,
    int compressionLevel,
  ) {
    return _ZSTD_createCDict(
      dictBuffer,
      dictSize,
      compressionLevel,
    );
  }

  late final _ZSTD_createCDictPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ZSTD_CDict> Function(
              ffi.Pointer<ffi.Void>, ffi.Size, ffi.Int)>>('ZSTD_createCDict');
  late final _ZSTD_createCDict = _ZSTD_createCDictPtr.asFunction<
      ffi.Pointer<ZSTD_CDict> Function(ffi.Pointer<ffi.Void>, int, int)>();

  /// ! ZSTD_freeCDict() :
  /// Function frees memory allocated by ZSTD_createCDict().
  /// If a NULL pointer is passed, no operation is performed.
  int ZSTD_freeCDict(
    ffi.Pointer<ZSTD_CDict> CDict,
  ) {
    return _ZSTD_freeCDict(
      CDict,
    );
  }

  late final _ZSTD_freeCDictPtr =
      _lookup<ffi.NativeFunction<ffi.Size Function(ffi.Pointer<ZSTD_CDict>)>>(
          'ZSTD_freeCDict');
  late final _ZSTD_freeCDict =
      _ZSTD_freeCDictPtr.asFunction<int Function(ffi.Pointer<ZSTD_CDict>)>();

  /// ! ZSTD_compress_usingCDict() :
  /// Compression using a digested Dictionary.
  /// Recommended when same dictionary is used multiple times.
  /// Note : compression level is _decided at dictionary creation time_,
  /// and frame parameters are hardcoded (dictID=yes, contentSize=yes, checksum=no)
  int ZSTD_compress_usingCDict(
    ffi.Pointer<ZSTD_CCtx> cctx,
    ffi.Pointer<ffi.Void> dst,
    int dstCapacity,
    ffi.Pointer<ffi.Void> src,
    int srcSize,
    ffi.Pointer<ZSTD_CDict> cdict,
  ) {
    return _ZSTD_compress_usingCDict(
      cctx,
      dst,
      dstCapacity,
      src,
      srcSize,
      cdict,
    );
  }

  late final _ZSTD_compress_usingCDictPtr = _lookup<
      ffi.NativeFunction<
          ffi.Size Function(
              ffi.Pointer<ZSTD_CCtx>,
              ffi.Pointer<ffi.Void>,
              ffi.Size,
              ffi.Pointer<ffi.Void>,
              ffi.Size,
              ffi.Pointer<ZSTD_CDict>)>>('ZSTD_compress_usingCDict');
  late final _ZSTD_compress_usingCDict =
      _ZSTD_compress_usingCDictPtr.asFunction<
          int Function(ffi.Pointer<ZSTD_CCtx>, ffi.Pointer<ffi.Void>, int,
              ffi.Pointer<ffi.Void>, int, ffi.Pointer<ZSTD_CDict>)>();

  /// ! ZSTD_createDDict() :
  /// Create a digested dictionary, ready to start decompression operation without startup delay.
  /// dictBuffer can be released after DDict creation, as its content is copied inside DDict.
  ffi.Pointer<ZSTD_DDict> ZSTD_createDDict(
    ffi.Pointer<ffi.Void> dictBuffer,
    int dictSize,
  ) {
    return _ZSTD_createDDict(
      dictBuffer,
      dictSize,
    );
  }

  late final _ZSTD_createDDictPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ZSTD_DDict> Function(
              ffi.Pointer<ffi.Void>, ffi.Size)>>('ZSTD_createDDict');
  late final _ZSTD_createDDict = _ZSTD_createDDictPtr.asFunction<
      ffi.Pointer<ZSTD_DDict> Function(ffi.Pointer<ffi.Void>, int)>();

  /// ! ZSTD_freeDDict() :
  /// Function frees memory allocated with ZSTD_createDDict()
  /// If a NULL pointer is passed, no operation is performed.
  int ZSTD_freeDDict(
    ffi.Pointer<ZSTD_DDict> ddict,
  ) {
    return _ZSTD_freeDDict(
      ddict,
    );
  }

  late final _ZSTD_freeDDictPtr =
      _lookup<ffi.NativeFunction<ffi.Size Function(ffi.Pointer<ZSTD_DDict>)>>(
          'ZSTD_freeDDict');
  late final _ZSTD_freeDDict =
      _ZSTD_freeDDictPtr.asFunction<int Function(ffi.Pointer<ZSTD_DDict>)>();

  /// ! ZSTD_decompress_usingDDict() :
  /// Decompression using a digested Dictionary.
  /// Recommended when same dictionary is used multiple times.
  int ZSTD_decompress_usingDDict(
    ffi.Pointer<ZSTD_DCtx> dctx,
    ffi.Pointer<ffi.Void> dst,
    int dstCapacity,
    ffi.Pointer<ffi.Void> src,
    int srcSize,
    ffi.Pointer<ZSTD_DDict> ddict,
  ) {
    return _ZSTD_decompress_usingDDict(
      dctx,
      dst,
      dstCapacity,
      src,
      srcSize,
      ddict,
    );
  }

  late final _ZSTD_decompress_usingDDictPtr = _lookup<
      ffi.NativeFunction<
          ffi.Size Function(
              ffi.Pointer<ZSTD_DCtx>,
              ffi.Pointer<ffi.Void>,
              ffi.Size,
              ffi.Pointer<ffi.Void>,
              ffi.Size,
              ffi.Pointer<ZSTD_DDict>)>>('ZSTD_decompress_usingDDict');
  late final _ZSTD_decompress_usingDDict =
      _ZSTD_decompress_usingDDictPtr.asFunction<
          int Function(ffi.Pointer<ZSTD_DCtx>, ffi.Pointer<ffi.Void>, int,
              ffi.Pointer<ffi.Void>, int, ffi.Pointer<ZSTD_DDict>)>();

  /// ! ZSTD_getDictID_fromDict() : Requires v1.4.0+
  /// Provides the dictID stored within dictionary.
  /// if @return == 0, the dictionary is not conformant with Zstandard specification.
  /// It can still be loaded, but as a content-only dictionary.
  int ZSTD_getDictID_fromDict(
    ffi.Pointer<ffi.Void> dict,
    int dictSize,
  ) {
    return _ZSTD_getDictID_fromDict(
      dict,
      dictSize,
    );
  }

  late final _ZSTD_getDictID_fromDictPtr = _lookup<
      ffi.NativeFunction<
          ffi.UnsignedInt Function(
              ffi.Pointer<ffi.Void>, ffi.Size)>>('ZSTD_getDictID_fromDict');
  late final _ZSTD_getDictID_fromDict = _ZSTD_getDictID_fromDictPtr.asFunction<
      int Function(ffi.Pointer<ffi.Void>, int)>();

  /// ! ZSTD_getDictID_fromCDict() : Requires v1.5.0+
  /// Provides the dictID of the dictionary loaded into `cdict`.
  /// If @return == 0, the dictionary is not conformant to Zstandard specification, or empty.
  /// Non-conformant dictionaries can still be loaded, but as content-only dictionaries.
  int ZSTD_getDictID_fromCDict(
    ffi.Pointer<ZSTD_CDict> cdict,
  ) {
    return _ZSTD_getDictID_fromCDict(
      cdict,
    );
  }

  late final _ZSTD_getDictID_fromCDictPtr = _lookup<
          ffi
          .NativeFunction<ffi.UnsignedInt Function(ffi.Pointer<ZSTD_CDict>)>>(
      'ZSTD_getDictID_fromCDict');
  late final _ZSTD_getDictID_fromCDict = _ZSTD_getDictID_fromCDictPtr
      .asFunction<int Function(ffi.Pointer<ZSTD_CDict>)>();

  /// ! ZSTD_getDictID_fromDDict() : Requires v1.4.0+
  /// Provides the dictID of the dictionary loaded into `ddict`.
  /// If @return == 0, the dictionary is not conformant to Zstandard specification, or empty.
  /// Non-conformant dictionaries can still be loaded, but as content-only dictionaries.
  int ZSTD_getDictID_fromDDict(
    ffi.Pointer<ZSTD_DDict> ddict,
  ) {
    return _ZSTD_getDictID_fromDDict(
      ddict,
    );
  }

  late final _ZSTD_getDictID_fromDDictPtr = _lookup<
          ffi
          .NativeFunction<ffi.UnsignedInt Function(ffi.Pointer<ZSTD_DDict>)>>(
      'ZSTD_getDictID_fromDDict');
  late final _ZSTD_getDictID_fromDDict = _ZSTD_getDictID_fromDDictPtr
      .asFunction<int Function(ffi.Pointer<ZSTD_DDict>)>();

  /// ! ZSTD_getDictID_fromFrame() : Requires v1.4.0+
  /// Provides the dictID required to decompressed the frame stored within `src`.
  /// If @return == 0, the dictID could not be decoded.
  /// This could for one of the following reasons :
  /// - The frame does not require a dictionary to be decoded (most common case).
  /// - The frame was built with dictID intentionally removed. Whatever dictionary is necessary is a hidden piece of information.
  /// Note : this use case also happens when using a non-conformant dictionary.
  /// - `srcSize` is too small, and as a result, the frame header could not be decoded (only possible if `srcSize < ZSTD_FRAMEHEADERSIZE_MAX`).
  /// - This is not a Zstandard frame.
  /// When identifying the exact failure cause, it's possible to use ZSTD_getFrameHeader(), which will provide a more precise error code.
  int ZSTD_getDictID_fromFrame(
    ffi.Pointer<ffi.Void> src,
    int srcSize,
  ) {
    return _ZSTD_getDictID_fromFrame(
      src,
      srcSize,
    );
  }

  late final _ZSTD_getDictID_fromFramePtr = _lookup<
      ffi.NativeFunction<
          ffi.UnsignedInt Function(
              ffi.Pointer<ffi.Void>, ffi.Size)>>('ZSTD_getDictID_fromFrame');
  late final _ZSTD_getDictID_fromFrame = _ZSTD_getDictID_fromFramePtr
      .asFunction<int Function(ffi.Pointer<ffi.Void>, int)>();

  /// ! ZSTD_CCtx_loadDictionary() : Requires v1.4.0+
  /// Create an internal CDict from `dict` buffer.
  /// Decompression will have to use same dictionary.
  /// @result : 0, or an error code (which can be tested with ZSTD_isError()).
  /// Special: Loading a NULL (or 0-size) dictionary invalidates previous dictionary,
  /// meaning "return to no-dictionary mode".
  /// Note 1 : Dictionary is sticky, it will be used for all future compressed frames,
  /// until parameters are reset, a new dictionary is loaded, or the dictionary
  /// is explicitly invalidated by loading a NULL dictionary.
  /// Note 2 : Loading a dictionary involves building tables.
  /// It's also a CPU consuming operation, with non-negligible impact on latency.
  /// Tables are dependent on compression parameters, and for this reason,
  /// compression parameters can no longer be changed after loading a dictionary.
  /// Note 3 :`dict` content will be copied internally.
  /// Use experimental ZSTD_CCtx_loadDictionary_byReference() to reference content instead.
  /// In such a case, dictionary buffer must outlive its users.
  /// Note 4 : Use ZSTD_CCtx_loadDictionary_advanced()
  /// to precisely select how dictionary content must be interpreted.
  /// Note 5 : This method does not benefit from LDM (long distance mode).
  /// If you want to employ LDM on some large dictionary content,
  /// prefer employing ZSTD_CCtx_refPrefix() described below.
  int ZSTD_CCtx_loadDictionary(
    ffi.Pointer<ZSTD_CCtx> cctx,
    ffi.Pointer<ffi.Void> dict,
    int dictSize,
  ) {
    return _ZSTD_CCtx_loadDictionary(
      cctx,
      dict,
      dictSize,
    );
  }

  late final _ZSTD_CCtx_loadDictionaryPtr = _lookup<
      ffi.NativeFunction<
          ffi.Size Function(ffi.Pointer<ZSTD_CCtx>, ffi.Pointer<ffi.Void>,
              ffi.Size)>>('ZSTD_CCtx_loadDictionary');
  late final _ZSTD_CCtx_loadDictionary =
      _ZSTD_CCtx_loadDictionaryPtr.asFunction<
          int Function(ffi.Pointer<ZSTD_CCtx>, ffi.Pointer<ffi.Void>, int)>();

  /// ! ZSTD_CCtx_refCDict() : Requires v1.4.0+
  /// Reference a prepared dictionary, to be used for all future compressed frames.
  /// Note that compression parameters are enforced from within CDict,
  /// and supersede any compression parameter previously set within CCtx.
  /// The parameters ignored are labelled as "superseded-by-cdict" in the ZSTD_cParameter enum docs.
  /// The ignored parameters will be used again if the CCtx is returned to no-dictionary mode.
  /// The dictionary will remain valid for future compressed frames using same CCtx.
  /// @result : 0, or an error code (which can be tested with ZSTD_isError()).
  /// Special : Referencing a NULL CDict means "return to no-dictionary mode".
  /// Note 1 : Currently, only one dictionary can be managed.
  /// Referencing a new dictionary effectively "discards" any previous one.
  /// Note 2 : CDict is just referenced, its lifetime must outlive its usage within CCtx.
  int ZSTD_CCtx_refCDict(
    ffi.Pointer<ZSTD_CCtx> cctx,
    ffi.Pointer<ZSTD_CDict> cdict,
  ) {
    return _ZSTD_CCtx_refCDict(
      cctx,
      cdict,
    );
  }

  late final _ZSTD_CCtx_refCDictPtr = _lookup<
      ffi.NativeFunction<
          ffi.Size Function(ffi.Pointer<ZSTD_CCtx>,
              ffi.Pointer<ZSTD_CDict>)>>('ZSTD_CCtx_refCDict');
  late final _ZSTD_CCtx_refCDict = _ZSTD_CCtx_refCDictPtr.asFunction<
      int Function(ffi.Pointer<ZSTD_CCtx>, ffi.Pointer<ZSTD_CDict>)>();

  /// ! ZSTD_CCtx_refPrefix() : Requires v1.4.0+
  /// Reference a prefix (single-usage dictionary) for next compressed frame.
  /// A prefix is **only used once**. Tables are discarded at end of frame (ZSTD_e_end).
  /// Decompression will need same prefix to properly regenerate data.
  /// Compressing with a prefix is similar in outcome as performing a diff and compressing it,
  /// but performs much faster, especially during decompression (compression speed is tunable with compression level).
  /// This method is compatible with LDM (long distance mode).
  /// @result : 0, or an error code (which can be tested with ZSTD_isError()).
  /// Special: Adding any prefix (including NULL) invalidates any previous prefix or dictionary
  /// Note 1 : Prefix buffer is referenced. It **must** outlive compression.
  /// Its content must remain unmodified during compression.
  /// Note 2 : If the intention is to diff some large src data blob with some prior version of itself,
  /// ensure that the window size is large enough to contain the entire source.
  /// See ZSTD_c_windowLog.
  /// Note 3 : Referencing a prefix involves building tables, which are dependent on compression parameters.
  /// It's a CPU consuming operation, with non-negligible impact on latency.
  /// If there is a need to use the same prefix multiple times, consider loadDictionary instead.
  /// Note 4 : By default, the prefix is interpreted as raw content (ZSTD_dct_rawContent).
  /// Use experimental ZSTD_CCtx_refPrefix_advanced() to alter dictionary interpretation.
  int ZSTD_CCtx_refPrefix(
    ffi.Pointer<ZSTD_CCtx> cctx,
    ffi.Pointer<ffi.Void> prefix,
    int prefixSize,
  ) {
    return _ZSTD_CCtx_refPrefix(
      cctx,
      prefix,
      prefixSize,
    );
  }

  late final _ZSTD_CCtx_refPrefixPtr = _lookup<
      ffi.NativeFunction<
          ffi.Size Function(ffi.Pointer<ZSTD_CCtx>, ffi.Pointer<ffi.Void>,
              ffi.Size)>>('ZSTD_CCtx_refPrefix');
  late final _ZSTD_CCtx_refPrefix = _ZSTD_CCtx_refPrefixPtr.asFunction<
      int Function(ffi.Pointer<ZSTD_CCtx>, ffi.Pointer<ffi.Void>, int)>();

  /// ! ZSTD_DCtx_loadDictionary() : Requires v1.4.0+
  /// Create an internal DDict from dict buffer, to be used to decompress all future frames.
  /// The dictionary remains valid for all future frames, until explicitly invalidated, or
  /// a new dictionary is loaded.
  /// @result : 0, or an error code (which can be tested with ZSTD_isError()).
  /// Special : Adding a NULL (or 0-size) dictionary invalidates any previous dictionary,
  /// meaning "return to no-dictionary mode".
  /// Note 1 : Loading a dictionary involves building tables,
  /// which has a non-negligible impact on CPU usage and latency.
  /// It's recommended to "load once, use many times", to amortize the cost
  /// Note 2 :`dict` content will be copied internally, so `dict` can be released after loading.
  /// Use ZSTD_DCtx_loadDictionary_byReference() to reference dictionary content instead.
  /// Note 3 : Use ZSTD_DCtx_loadDictionary_advanced() to take control of
  /// how dictionary content is loaded and interpreted.
  int ZSTD_DCtx_loadDictionary(
    ffi.Pointer<ZSTD_DCtx> dctx,
    ffi.Pointer<ffi.Void> dict,
    int dictSize,
  ) {
    return _ZSTD_DCtx_loadDictionary(
      dctx,
      dict,
      dictSize,
    );
  }

  late final _ZSTD_DCtx_loadDictionaryPtr = _lookup<
      ffi.NativeFunction<
          ffi.Size Function(ffi.Pointer<ZSTD_DCtx>, ffi.Pointer<ffi.Void>,
              ffi.Size)>>('ZSTD_DCtx_loadDictionary');
  late final _ZSTD_DCtx_loadDictionary =
      _ZSTD_DCtx_loadDictionaryPtr.asFunction<
          int Function(ffi.Pointer<ZSTD_DCtx>, ffi.Pointer<ffi.Void>, int)>();

  /// ! ZSTD_DCtx_refDDict() : Requires v1.4.0+
  /// Reference a prepared dictionary, to be used to decompress next frames.
  /// The dictionary remains active for decompression of future frames using same DCtx.
  ///
  /// If called with ZSTD_d_refMultipleDDicts enabled, repeated calls of this function
  /// will store the DDict references in a table, and the DDict used for decompression
  /// will be determined at decompression time, as per the dict ID in the frame.
  /// The memory for the table is allocated on the first call to refDDict, and can be
  /// freed with ZSTD_freeDCtx().
  ///
  /// If called with ZSTD_d_refMultipleDDicts disabled (the default), only one dictionary
  /// will be managed, and referencing a dictionary effectively "discards" any previous one.
  ///
  /// @result : 0, or an error code (which can be tested with ZSTD_isError()).
  /// Special: referencing a NULL DDict means "return to no-dictionary mode".
  /// Note 2 : DDict is just referenced, its lifetime must outlive its usage from DCtx.
  int ZSTD_DCtx_refDDict(
    ffi.Pointer<ZSTD_DCtx> dctx,
    ffi.Pointer<ZSTD_DDict> ddict,
  ) {
    return _ZSTD_DCtx_refDDict(
      dctx,
      ddict,
    );
  }

  late final _ZSTD_DCtx_refDDictPtr = _lookup<
      ffi.NativeFunction<
          ffi.Size Function(ffi.Pointer<ZSTD_DCtx>,
              ffi.Pointer<ZSTD_DDict>)>>('ZSTD_DCtx_refDDict');
  late final _ZSTD_DCtx_refDDict = _ZSTD_DCtx_refDDictPtr.asFunction<
      int Function(ffi.Pointer<ZSTD_DCtx>, ffi.Pointer<ZSTD_DDict>)>();

  /// ! ZSTD_DCtx_refPrefix() : Requires v1.4.0+
  /// Reference a prefix (single-usage dictionary) to decompress next frame.
  /// This is the reverse operation of ZSTD_CCtx_refPrefix(),
  /// and must use the same prefix as the one used during compression.
  /// Prefix is **only used once**. Reference is discarded at end of frame.
  /// End of frame is reached when ZSTD_decompressStream() returns 0.
  /// @result : 0, or an error code (which can be tested with ZSTD_isError()).
  /// Note 1 : Adding any prefix (including NULL) invalidates any previously set prefix or dictionary
  /// Note 2 : Prefix buffer is referenced. It **must** outlive decompression.
  /// Prefix buffer must remain unmodified up to the end of frame,
  /// reached when ZSTD_decompressStream() returns 0.
  /// Note 3 : By default, the prefix is treated as raw content (ZSTD_dct_rawContent).
  /// Use ZSTD_CCtx_refPrefix_advanced() to alter dictMode (Experimental section)
  /// Note 4 : Referencing a raw content prefix has almost no cpu nor memory cost.
  /// A full dictionary is more costly, as it requires building tables.
  int ZSTD_DCtx_refPrefix(
    ffi.Pointer<ZSTD_DCtx> dctx,
    ffi.Pointer<ffi.Void> prefix,
    int prefixSize,
  ) {
    return _ZSTD_DCtx_refPrefix(
      dctx,
      prefix,
      prefixSize,
    );
  }

  late final _ZSTD_DCtx_refPrefixPtr = _lookup<
      ffi.NativeFunction<
          ffi.Size Function(ffi.Pointer<ZSTD_DCtx>, ffi.Pointer<ffi.Void>,
              ffi.Size)>>('ZSTD_DCtx_refPrefix');
  late final _ZSTD_DCtx_refPrefix = _ZSTD_DCtx_refPrefixPtr.asFunction<
      int Function(ffi.Pointer<ZSTD_DCtx>, ffi.Pointer<ffi.Void>, int)>();

  /// ! ZSTD_sizeof_*() : Requires v1.4.0+
  /// These functions give the _current_ memory usage of selected object.
  /// Note that object memory usage can evolve (increase or decrease) over time.
  int ZSTD_sizeof_CCtx(
    ffi.Pointer<ZSTD_CCtx> cctx,
  ) {
    return _ZSTD_sizeof_CCtx(
      cctx,
    );
  }

  late final _ZSTD_sizeof_CCtxPtr =
      _lookup<ffi.NativeFunction<ffi.Size Function(ffi.Pointer<ZSTD_CCtx>)>>(
          'ZSTD_sizeof_CCtx');
  late final _ZSTD_sizeof_CCtx =
      _ZSTD_sizeof_CCtxPtr.asFunction<int Function(ffi.Pointer<ZSTD_CCtx>)>();

  int ZSTD_sizeof_DCtx(
    ffi.Pointer<ZSTD_DCtx> dctx,
  ) {
    return _ZSTD_sizeof_DCtx(
      dctx,
    );
  }

  late final _ZSTD_sizeof_DCtxPtr =
      _lookup<ffi.NativeFunction<ffi.Size Function(ffi.Pointer<ZSTD_DCtx>)>>(
          'ZSTD_sizeof_DCtx');
  late final _ZSTD_sizeof_DCtx =
      _ZSTD_sizeof_DCtxPtr.asFunction<int Function(ffi.Pointer<ZSTD_DCtx>)>();

  int ZSTD_sizeof_CStream(
    ffi.Pointer<ZSTD_CStream> zcs,
  ) {
    return _ZSTD_sizeof_CStream(
      zcs,
    );
  }

  late final _ZSTD_sizeof_CStreamPtr =
      _lookup<ffi.NativeFunction<ffi.Size Function(ffi.Pointer<ZSTD_CStream>)>>(
          'ZSTD_sizeof_CStream');
  late final _ZSTD_sizeof_CStream = _ZSTD_sizeof_CStreamPtr.asFunction<
      int Function(ffi.Pointer<ZSTD_CStream>)>();

  int ZSTD_sizeof_DStream(
    ffi.Pointer<ZSTD_DStream> zds,
  ) {
    return _ZSTD_sizeof_DStream(
      zds,
    );
  }

  late final _ZSTD_sizeof_DStreamPtr =
      _lookup<ffi.NativeFunction<ffi.Size Function(ffi.Pointer<ZSTD_DStream>)>>(
          'ZSTD_sizeof_DStream');
  late final _ZSTD_sizeof_DStream = _ZSTD_sizeof_DStreamPtr.asFunction<
      int Function(ffi.Pointer<ZSTD_DStream>)>();

  int ZSTD_sizeof_CDict(
    ffi.Pointer<ZSTD_CDict> cdict,
  ) {
    return _ZSTD_sizeof_CDict(
      cdict,
    );
  }

  late final _ZSTD_sizeof_CDictPtr =
      _lookup<ffi.NativeFunction<ffi.Size Function(ffi.Pointer<ZSTD_CDict>)>>(
          'ZSTD_sizeof_CDict');
  late final _ZSTD_sizeof_CDict =
      _ZSTD_sizeof_CDictPtr.asFunction<int Function(ffi.Pointer<ZSTD_CDict>)>();

  int ZSTD_sizeof_DDict(
    ffi.Pointer<ZSTD_DDict> ddict,
  ) {
    return _ZSTD_sizeof_DDict(
      ddict,
    );
  }

  late final _ZSTD_sizeof_DDictPtr =
      _lookup<ffi.NativeFunction<ffi.Size Function(ffi.Pointer<ZSTD_DDict>)>>(
          'ZSTD_sizeof_DDict');
  late final _ZSTD_sizeof_DDict =
      _ZSTD_sizeof_DDictPtr.asFunction<int Function(ffi.Pointer<ZSTD_DDict>)>();
}

/// -*********************************************
/// Error codes list
/// -*********************************************
/// Error codes _values_ are pinned down since v1.3.1 only.
/// Therefore, don't rely on values if you may link to any version < v1.3.1.
///
/// Only values < 100 are considered stable.
///
/// note 1 : this API shall be used with static linking only.
/// dynamic linking is not yet officially supported.
/// note 2 : Prefer relying on the enum than on its value whenever possible
/// This is the only supported way to use the error list < v1.3.1
/// note 3 : ZSTD_isError() is always correct, whatever the library version.
enum ZSTD_ErrorCode {
  ZSTD_error_no_error(0),
  ZSTD_error_GENERIC(1),
  ZSTD_error_prefix_unknown(10),
  ZSTD_error_version_unsupported(12),
  ZSTD_error_frameParameter_unsupported(14),
  ZSTD_error_frameParameter_windowTooLarge(16),
  ZSTD_error_corruption_detected(20),
  ZSTD_error_checksum_wrong(22),
  ZSTD_error_literals_headerWrong(24),
  ZSTD_error_dictionary_corrupted(30),
  ZSTD_error_dictionary_wrong(32),
  ZSTD_error_dictionaryCreation_failed(34),
  ZSTD_error_parameter_unsupported(40),
  ZSTD_error_parameter_combination_unsupported(41),
  ZSTD_error_parameter_outOfBound(42),
  ZSTD_error_tableLog_tooLarge(44),
  ZSTD_error_maxSymbolValue_tooLarge(46),
  ZSTD_error_maxSymbolValue_tooSmall(48),
  ZSTD_error_cannotProduce_uncompressedBlock(49),
  ZSTD_error_stabilityCondition_notRespected(50),
  ZSTD_error_stage_wrong(60),
  ZSTD_error_init_missing(62),
  ZSTD_error_memory_allocation(64),
  ZSTD_error_workSpace_tooSmall(66),
  ZSTD_error_dstSize_tooSmall(70),
  ZSTD_error_srcSize_wrong(72),
  ZSTD_error_dstBuffer_null(74),
  ZSTD_error_noForwardProgress_destFull(80),
  ZSTD_error_noForwardProgress_inputEmpty(82),

  /// following error codes are __NOT STABLE__, they can be removed or changed in future versions
  ZSTD_error_frameIndex_tooLarge(100),
  ZSTD_error_seekableIO(102),
  ZSTD_error_dstBuffer_wrong(104),
  ZSTD_error_srcBuffer_wrong(105),
  ZSTD_error_sequenceProducer_failed(106),
  ZSTD_error_externalSequences_invalid(107),

  /// never EVER use this value directly, it can change in future versions! Use ZSTD_isError() instead
  ZSTD_error_maxCode(120);

  final int value;
  const ZSTD_ErrorCode(this.value);

  static ZSTD_ErrorCode fromValue(int value) => switch (value) {
        0 => ZSTD_error_no_error,
        1 => ZSTD_error_GENERIC,
        10 => ZSTD_error_prefix_unknown,
        12 => ZSTD_error_version_unsupported,
        14 => ZSTD_error_frameParameter_unsupported,
        16 => ZSTD_error_frameParameter_windowTooLarge,
        20 => ZSTD_error_corruption_detected,
        22 => ZSTD_error_checksum_wrong,
        24 => ZSTD_error_literals_headerWrong,
        30 => ZSTD_error_dictionary_corrupted,
        32 => ZSTD_error_dictionary_wrong,
        34 => ZSTD_error_dictionaryCreation_failed,
        40 => ZSTD_error_parameter_unsupported,
        41 => ZSTD_error_parameter_combination_unsupported,
        42 => ZSTD_error_parameter_outOfBound,
        44 => ZSTD_error_tableLog_tooLarge,
        46 => ZSTD_error_maxSymbolValue_tooLarge,
        48 => ZSTD_error_maxSymbolValue_tooSmall,
        49 => ZSTD_error_cannotProduce_uncompressedBlock,
        50 => ZSTD_error_stabilityCondition_notRespected,
        60 => ZSTD_error_stage_wrong,
        62 => ZSTD_error_init_missing,
        64 => ZSTD_error_memory_allocation,
        66 => ZSTD_error_workSpace_tooSmall,
        70 => ZSTD_error_dstSize_tooSmall,
        72 => ZSTD_error_srcSize_wrong,
        74 => ZSTD_error_dstBuffer_null,
        80 => ZSTD_error_noForwardProgress_destFull,
        82 => ZSTD_error_noForwardProgress_inputEmpty,
        100 => ZSTD_error_frameIndex_tooLarge,
        102 => ZSTD_error_seekableIO,
        104 => ZSTD_error_dstBuffer_wrong,
        105 => ZSTD_error_srcBuffer_wrong,
        106 => ZSTD_error_sequenceProducer_failed,
        107 => ZSTD_error_externalSequences_invalid,
        120 => ZSTD_error_maxCode,
        _ => throw ArgumentError('Unknown value for ZSTD_ErrorCode: $value'),
      };
}

final class ZSTD_CCtx_s extends ffi.Opaque {}

/// Explicit context
/// /
/// /*= Compression context
/// When compressing many times,
/// it is recommended to allocate a compression context just once,
/// and reuse it for each successive compression operation.
/// This will make the workload easier for system's memory.
/// Note : re-using context is just a speed / resource optimization.
/// It doesn't change the compression ratio, which remains identical.
/// Note 2: For parallel execution in multi-threaded environments,
/// use one different context per thread .
typedef ZSTD_CCtx = ZSTD_CCtx_s;

final class ZSTD_DCtx_s extends ffi.Opaque {}

/// = Decompression context
/// When decompressing many times,
/// it is recommended to allocate a context only once,
/// and reuse it for each successive compression operation.
/// This will make workload friendlier for system's memory.
/// Use one context per thread for parallel execution.
typedef ZSTD_DCtx = ZSTD_DCtx_s;

/// Compression strategies, listed from fastest to strongest
enum ZSTD_strategy {
  ZSTD_fast(1),
  ZSTD_dfast(2),
  ZSTD_greedy(3),
  ZSTD_lazy(4),
  ZSTD_lazy2(5),
  ZSTD_btlazy2(6),
  ZSTD_btopt(7),
  ZSTD_btultra(8),
  ZSTD_btultra2(9);

  final int value;
  const ZSTD_strategy(this.value);

  static ZSTD_strategy fromValue(int value) => switch (value) {
        1 => ZSTD_fast,
        2 => ZSTD_dfast,
        3 => ZSTD_greedy,
        4 => ZSTD_lazy,
        5 => ZSTD_lazy2,
        6 => ZSTD_btlazy2,
        7 => ZSTD_btopt,
        8 => ZSTD_btultra,
        9 => ZSTD_btultra2,
        _ => throw ArgumentError('Unknown value for ZSTD_strategy: $value'),
      };
}

enum ZSTD_cParameter {
  /// Set compression parameters according to pre-defined cLevel table.
  /// Note that exact compression parameters are dynamically determined,
  /// depending on both compression level and srcSize (when known).
  /// Default level is ZSTD_CLEVEL_DEFAULT==3.
  /// Special: value 0 means default, which is controlled by ZSTD_CLEVEL_DEFAULT.
  /// Note 1 : it's possible to pass a negative compression level.
  /// Note 2 : setting a level does not automatically set all other compression parameters
  /// to default. Setting this will however eventually dynamically impact the compression
  /// parameters which have not been manually set. The manually set
  /// ones will 'stick'.
  ZSTD_c_compressionLevel(100),

  /// Maximum allowed back-reference distance, expressed as power of 2.
  /// This will set a memory budget for streaming decompression,
  /// with larger values requiring more memory
  /// and typically compressing more.
  /// Must be clamped between ZSTD_WINDOWLOG_MIN and ZSTD_WINDOWLOG_MAX.
  /// Special: value 0 means "use default windowLog".
  /// Note: Using a windowLog greater than ZSTD_WINDOWLOG_LIMIT_DEFAULT
  /// requires explicitly allowing such size at streaming decompression stage.
  ZSTD_c_windowLog(101),

  /// Size of the initial probe table, as a power of 2.
  /// Resulting memory usage is (1 << (hashLog+2)).
  /// Must be clamped between ZSTD_HASHLOG_MIN and ZSTD_HASHLOG_MAX.
  /// Larger tables improve compression ratio of strategies <= dFast,
  /// and improve speed of strategies > dFast.
  /// Special: value 0 means "use default hashLog".
  ZSTD_c_hashLog(102),

  /// Size of the multi-probe search table, as a power of 2.
  /// Resulting memory usage is (1 << (chainLog+2)).
  /// Must be clamped between ZSTD_CHAINLOG_MIN and ZSTD_CHAINLOG_MAX.
  /// Larger tables result in better and slower compression.
  /// This parameter is useless for "fast" strategy.
  /// It's still useful when using "dfast" strategy,
  /// in which case it defines a secondary probe table.
  /// Special: value 0 means "use default chainLog".
  ZSTD_c_chainLog(103),

  /// Number of search attempts, as a power of 2.
  /// More attempts result in better and slower compression.
  /// This parameter is useless for "fast" and "dFast" strategies.
  /// Special: value 0 means "use default searchLog".
  ZSTD_c_searchLog(104),

  /// Minimum size of searched matches.
  /// Note that Zstandard can still find matches of smaller size,
  /// it just tweaks its search algorithm to look for this size and larger.
  /// Larger values increase compression and decompression speed, but decrease ratio.
  /// Must be clamped between ZSTD_MINMATCH_MIN and ZSTD_MINMATCH_MAX.
  /// Note that currently, for all strategies < btopt, effective minimum is 4.
  /// , for all strategies > fast, effective maximum is 6.
  /// Special: value 0 means "use default minMatchLength".
  ZSTD_c_minMatch(105),

  /// Impact of this field depends on strategy.
  /// For strategies btopt, btultra & btultra2:
  /// Length of Match considered "good enough" to stop search.
  /// Larger values make compression stronger, and slower.
  /// For strategy fast:
  /// Distance between match sampling.
  /// Larger values make compression faster, and weaker.
  /// Special: value 0 means "use default targetLength".
  ZSTD_c_targetLength(106),

  /// See ZSTD_strategy enum definition.
  /// The higher the value of selected strategy, the more complex it is,
  /// resulting in stronger and slower compression.
  /// Special: value 0 means "use default strategy".
  ZSTD_c_strategy(107),

  /// v1.5.6+
  /// Attempts to fit compressed block size into approximately targetCBlockSize.
  /// Bound by ZSTD_TARGETCBLOCKSIZE_MIN and ZSTD_TARGETCBLOCKSIZE_MAX.
  /// Note that it's not a guarantee, just a convergence target (default:0).
  /// No target when targetCBlockSize == 0.
  /// This is helpful in low bandwidth streaming environments to improve end-to-end latency,
  /// when a client can make use of partial documents (a prominent example being Chrome).
  /// Note: this parameter is stable since v1.5.6.
  /// It was present as an experimental parameter in earlier versions,
  /// but it's not recommended using it with earlier library versions
  /// due to massive performance regressions.
  ZSTD_c_targetCBlockSize(130),

  /// Enable long distance matching.
  /// This parameter is designed to improve compression ratio
  /// for large inputs, by finding large matches at long distance.
  /// It increases memory usage and window size.
  /// Note: enabling this parameter increases default ZSTD_c_windowLog to 128 MB
  /// except when expressly set to a different value.
  /// Note: will be enabled by default if ZSTD_c_windowLog >= 128 MB and
  /// compression strategy >= ZSTD_btopt (== compression level 16+)
  ZSTD_c_enableLongDistanceMatching(160),

  /// Size of the table for long distance matching, as a power of 2.
  /// Larger values increase memory usage and compression ratio,
  /// but decrease compression speed.
  /// Must be clamped between ZSTD_HASHLOG_MIN and ZSTD_HASHLOG_MAX
  /// default: windowlog - 7.
  /// Special: value 0 means "automatically determine hashlog".
  ZSTD_c_ldmHashLog(161),

  /// Minimum match size for long distance matcher.
  /// Larger/too small values usually decrease compression ratio.
  /// Must be clamped between ZSTD_LDM_MINMATCH_MIN and ZSTD_LDM_MINMATCH_MAX.
  /// Special: value 0 means "use default value" (default: 64).
  ZSTD_c_ldmMinMatch(162),

  /// Log size of each bucket in the LDM hash table for collision resolution.
  /// Larger values improve collision resolution but decrease compression speed.
  /// The maximum value is ZSTD_LDM_BUCKETSIZELOG_MAX.
  /// Special: value 0 means "use default value" (default: 3).
  ZSTD_c_ldmBucketSizeLog(163),

  /// Frequency of inserting/looking up entries into the LDM hash table.
  /// Must be clamped between 0 and (ZSTD_WINDOWLOG_MAX - ZSTD_HASHLOG_MIN).
  /// Default is MAX(0, (windowLog - ldmHashLog)), optimizing hash table usage.
  /// Larger values improve compression speed.
  /// Deviating far from default value will likely result in a compression ratio decrease.
  /// Special: value 0 means "automatically determine hashRateLog".
  ZSTD_c_ldmHashRateLog(164),

  /// Content size will be written into frame header _whenever known_ (default:1)
  /// Content size must be known at the beginning of compression.
  /// This is automatically the case when using ZSTD_compress2(),
  /// For streaming scenarios, content size must be provided with ZSTD_CCtx_setPledgedSrcSize()
  ZSTD_c_contentSizeFlag(200),

  /// A 32-bits checksum of content is written at end of frame (default:0)
  ZSTD_c_checksumFlag(201),

  /// When applicable, dictionary's ID is written into frame header (default:1)
  ZSTD_c_dictIDFlag(202),

  /// Select how many threads will be spawned to compress in parallel.
  /// When nbWorkers >= 1, triggers asynchronous mode when invoking ZSTD_compressStream*() :
  /// ZSTD_compressStream*() consumes input and flush output if possible, but immediately gives back control to caller,
  /// while compression is performed in parallel, within worker thread(s).
  /// (note : a strong exception to this rule is when first invocation of ZSTD_compressStream2() sets ZSTD_e_end :
  /// in which case, ZSTD_compressStream2() delegates to ZSTD_compress2(), which is always a blocking call).
  /// More workers improve speed, but also increase memory usage.
  /// Default value is `0`, aka "single-threaded mode" : no worker is spawned,
  /// compression is performed inside Caller's thread, and all invocations are blocking
  ZSTD_c_nbWorkers(400),

  /// Size of a compression job. This value is enforced only when nbWorkers >= 1.
  /// Each compression job is completed in parallel, so this value can indirectly impact the nb of active threads.
  /// 0 means default, which is dynamically determined based on compression parameters.
  /// Job size must be a minimum of overlap size, or ZSTDMT_JOBSIZE_MIN (= 512 KB), whichever is largest.
  /// The minimum size is automatically and transparently enforced.
  ZSTD_c_jobSize(401),

  /// Control the overlap size, as a fraction of window size.
  /// The overlap size is an amount of data reloaded from previous job at the beginning of a new job.
  /// It helps preserve compression ratio, while each job is compressed in parallel.
  /// This value is enforced only when nbWorkers >= 1.
  /// Larger values increase compression ratio, but decrease speed.
  /// Possible values range from 0 to 9 :
  /// - 0 means "default" : value will be determined by the library, depending on strategy
  /// - 1 means "no overlap"
  /// - 9 means "full overlap", using a full window size.
  /// Each intermediate rank increases/decreases load size by a factor 2 :
  /// 9: full window;  8: w/2;  7: w/4;  6: w/8;  5:w/16;  4: w/32;  3:w/64;  2:w/128;  1:no overlap;  0:default
  /// default value varies between 6 and 9, depending on strategy
  ZSTD_c_overlapLog(402),

  /// note : additional experimental parameters are also available
  /// within the experimental section of the API.
  /// At the time of this writing, they include :
  /// ZSTD_c_rsyncable
  /// ZSTD_c_format
  /// ZSTD_c_forceMaxWindow
  /// ZSTD_c_forceAttachDict
  /// ZSTD_c_literalCompressionMode
  /// ZSTD_c_srcSizeHint
  /// ZSTD_c_enableDedicatedDictSearch
  /// ZSTD_c_stableInBuffer
  /// ZSTD_c_stableOutBuffer
  /// ZSTD_c_blockDelimiters
  /// ZSTD_c_validateSequences
  /// ZSTD_c_blockSplitterLevel
  /// ZSTD_c_splitAfterSequences
  /// ZSTD_c_useRowMatchFinder
  /// ZSTD_c_prefetchCDictTables
  /// ZSTD_c_enableSeqProducerFallback
  /// ZSTD_c_maxBlockSize
  /// Because they are not stable, it's necessary to define ZSTD_STATIC_LINKING_ONLY to access them.
  /// note : never ever use experimentalParam? names directly;
  /// also, the enums values themselves are unstable and can still change.
  ZSTD_c_experimentalParam1(500),
  ZSTD_c_experimentalParam2(10),
  ZSTD_c_experimentalParam3(1000),
  ZSTD_c_experimentalParam4(1001),
  ZSTD_c_experimentalParam5(1002),

  /// was ZSTD_c_experimentalParam6=1003; is now ZSTD_c_targetCBlockSize
  ZSTD_c_experimentalParam7(1004),
  ZSTD_c_experimentalParam8(1005),
  ZSTD_c_experimentalParam9(1006),
  ZSTD_c_experimentalParam10(1007),
  ZSTD_c_experimentalParam11(1008),
  ZSTD_c_experimentalParam12(1009),
  ZSTD_c_experimentalParam13(1010),
  ZSTD_c_experimentalParam14(1011),
  ZSTD_c_experimentalParam15(1012),
  ZSTD_c_experimentalParam16(1013),
  ZSTD_c_experimentalParam17(1014),
  ZSTD_c_experimentalParam18(1015),
  ZSTD_c_experimentalParam19(1016),
  ZSTD_c_experimentalParam20(1017);

  final int value;
  const ZSTD_cParameter(this.value);

  static ZSTD_cParameter fromValue(int value) => switch (value) {
        100 => ZSTD_c_compressionLevel,
        101 => ZSTD_c_windowLog,
        102 => ZSTD_c_hashLog,
        103 => ZSTD_c_chainLog,
        104 => ZSTD_c_searchLog,
        105 => ZSTD_c_minMatch,
        106 => ZSTD_c_targetLength,
        107 => ZSTD_c_strategy,
        130 => ZSTD_c_targetCBlockSize,
        160 => ZSTD_c_enableLongDistanceMatching,
        161 => ZSTD_c_ldmHashLog,
        162 => ZSTD_c_ldmMinMatch,
        163 => ZSTD_c_ldmBucketSizeLog,
        164 => ZSTD_c_ldmHashRateLog,
        200 => ZSTD_c_contentSizeFlag,
        201 => ZSTD_c_checksumFlag,
        202 => ZSTD_c_dictIDFlag,
        400 => ZSTD_c_nbWorkers,
        401 => ZSTD_c_jobSize,
        402 => ZSTD_c_overlapLog,
        500 => ZSTD_c_experimentalParam1,
        10 => ZSTD_c_experimentalParam2,
        1000 => ZSTD_c_experimentalParam3,
        1001 => ZSTD_c_experimentalParam4,
        1002 => ZSTD_c_experimentalParam5,
        1004 => ZSTD_c_experimentalParam7,
        1005 => ZSTD_c_experimentalParam8,
        1006 => ZSTD_c_experimentalParam9,
        1007 => ZSTD_c_experimentalParam10,
        1008 => ZSTD_c_experimentalParam11,
        1009 => ZSTD_c_experimentalParam12,
        1010 => ZSTD_c_experimentalParam13,
        1011 => ZSTD_c_experimentalParam14,
        1012 => ZSTD_c_experimentalParam15,
        1013 => ZSTD_c_experimentalParam16,
        1014 => ZSTD_c_experimentalParam17,
        1015 => ZSTD_c_experimentalParam18,
        1016 => ZSTD_c_experimentalParam19,
        1017 => ZSTD_c_experimentalParam20,
        _ => throw ArgumentError('Unknown value for ZSTD_cParameter: $value'),
      };
}

final class ZSTD_bounds extends ffi.Struct {
  @ffi.Size()
  external int error;

  @ffi.Int()
  external int lowerBound;

  @ffi.Int()
  external int upperBound;
}

enum ZSTD_ResetDirective {
  ZSTD_reset_session_only(1),
  ZSTD_reset_parameters(2),
  ZSTD_reset_session_and_parameters(3);

  final int value;
  const ZSTD_ResetDirective(this.value);

  static ZSTD_ResetDirective fromValue(int value) => switch (value) {
        1 => ZSTD_reset_session_only,
        2 => ZSTD_reset_parameters,
        3 => ZSTD_reset_session_and_parameters,
        _ =>
          throw ArgumentError('Unknown value for ZSTD_ResetDirective: $value'),
      };
}

/// The advanced API pushes parameters one by one into an existing DCtx context.
/// Parameters are sticky, and remain valid for all following frames
/// using the same DCtx context.
/// It's possible to reset parameters to default values using ZSTD_DCtx_reset().
/// Note : This API is compatible with existing ZSTD_decompressDCtx() and ZSTD_decompressStream().
/// Therefore, no new decompression function is necessary.
enum ZSTD_dParameter {
  /// Select a size limit (in power of 2) beyond which
  /// the streaming API will refuse to allocate memory buffer
  /// in order to protect the host from unreasonable memory requirements.
  /// This parameter is only useful in streaming mode, since no internal buffer is allocated in single-pass mode.
  /// By default, a decompression context accepts window sizes <= (1 << ZSTD_WINDOWLOG_LIMIT_DEFAULT).
  /// Special: value 0 means "use default maximum windowLog".
  ZSTD_d_windowLogMax(100),

  /// note : additional experimental parameters are also available
  /// within the experimental section of the API.
  /// At the time of this writing, they include :
  /// ZSTD_d_format
  /// ZSTD_d_stableOutBuffer
  /// ZSTD_d_forceIgnoreChecksum
  /// ZSTD_d_refMultipleDDicts
  /// ZSTD_d_disableHuffmanAssembly
  /// ZSTD_d_maxBlockSize
  /// Because they are not stable, it's necessary to define ZSTD_STATIC_LINKING_ONLY to access them.
  /// note : never ever use experimentalParam? names directly
  ZSTD_d_experimentalParam1(1000),
  ZSTD_d_experimentalParam2(1001),
  ZSTD_d_experimentalParam3(1002),
  ZSTD_d_experimentalParam4(1003),
  ZSTD_d_experimentalParam5(1004),
  ZSTD_d_experimentalParam6(1005);

  final int value;
  const ZSTD_dParameter(this.value);

  static ZSTD_dParameter fromValue(int value) => switch (value) {
        100 => ZSTD_d_windowLogMax,
        1000 => ZSTD_d_experimentalParam1,
        1001 => ZSTD_d_experimentalParam2,
        1002 => ZSTD_d_experimentalParam3,
        1003 => ZSTD_d_experimentalParam4,
        1004 => ZSTD_d_experimentalParam5,
        1005 => ZSTD_d_experimentalParam6,
        _ => throw ArgumentError('Unknown value for ZSTD_dParameter: $value'),
      };
}

/// Streaming
final class ZSTD_inBuffer_s extends ffi.Struct {
  /// < start of input buffer
  external ffi.Pointer<ffi.Void> src;

  /// < size of input buffer
  @ffi.Size()
  external int size;

  /// < position where reading stopped. Will be updated. Necessarily 0 <= pos <= size
  @ffi.Size()
  external int pos;
}

/// Streaming
typedef ZSTD_inBuffer = ZSTD_inBuffer_s;

final class ZSTD_outBuffer_s extends ffi.Struct {
  /// < start of output buffer
  external ffi.Pointer<ffi.Void> dst;

  /// < size of output buffer
  @ffi.Size()
  external int size;

  /// < position where writing stopped. Will be updated. Necessarily 0 <= pos <= size
  @ffi.Size()
  external int pos;
}

typedef ZSTD_outBuffer = ZSTD_outBuffer_s;

/// -***********************************************************************
/// Streaming compression - HowTo
///
/// A ZSTD_CStream object is required to track streaming operation.
/// Use ZSTD_createCStream() and ZSTD_freeCStream() to create/release resources.
/// ZSTD_CStream objects can be reused multiple times on consecutive compression operations.
/// It is recommended to reuse ZSTD_CStream since it will play nicer with system's memory, by re-using already allocated memory.
///
/// For parallel execution, use one separate ZSTD_CStream per thread.
///
/// note : since v1.3.0, ZSTD_CStream and ZSTD_CCtx are the same thing.
///
/// Parameters are sticky : when starting a new compression on the same context,
/// it will reuse the same sticky parameters as previous compression session.
/// When in doubt, it's recommended to fully initialize the context before usage.
/// Use ZSTD_CCtx_reset() to reset the context and ZSTD_CCtx_setParameter(),
/// ZSTD_CCtx_setPledgedSrcSize(), or ZSTD_CCtx_loadDictionary() and friends to
/// set more specific parameters, the pledged source size, or load a dictionary.
///
/// Use ZSTD_compressStream2() with ZSTD_e_continue as many times as necessary to
/// consume input stream. The function will automatically update both `pos`
/// fields within `input` and `output`.
/// Note that the function may not consume the entire input, for example, because
/// the output buffer is already full, in which case `input.pos < input.size`.
/// The caller must check if input has been entirely consumed.
/// If not, the caller must make some room to receive more compressed data,
/// and then present again remaining input data.
/// note: ZSTD_e_continue is guaranteed to make some forward progress when called,
/// but doesn't guarantee maximal forward progress. This is especially relevant
/// when compressing with multiple threads. The call won't block if it can
/// consume some input, but if it can't it will wait for some, but not all,
/// output to be flushed.
/// @return : provides a minimum amount of data remaining to be flushed from internal buffers
/// or an error code, which can be tested using ZSTD_isError().
///
/// At any moment, it's possible to flush whatever data might remain stuck within internal buffer,
/// using ZSTD_compressStream2() with ZSTD_e_flush. `output->pos` will be updated.
/// Note that, if `output->size` is too small, a single invocation with ZSTD_e_flush might not be enough (return code > 0).
/// In which case, make some room to receive more compressed data, and call again ZSTD_compressStream2() with ZSTD_e_flush.
/// You must continue calling ZSTD_compressStream2() with ZSTD_e_flush until it returns 0, at which point you can change the
/// operation.
/// note: ZSTD_e_flush will flush as much output as possible, meaning when compressing with multiple threads, it will
/// block until the flush is complete or the output buffer is full.
/// @return : 0 if internal buffers are entirely flushed,
/// >0 if some data still present within internal buffer (the value is minimal estimation of remaining size),
/// or an error code, which can be tested using ZSTD_isError().
///
/// Calling ZSTD_compressStream2() with ZSTD_e_end instructs to finish a frame.
/// It will perform a flush and write frame epilogue.
/// The epilogue is required for decoders to consider a frame completed.
/// flush operation is the same, and follows same rules as calling ZSTD_compressStream2() with ZSTD_e_flush.
/// You must continue calling ZSTD_compressStream2() with ZSTD_e_end until it returns 0, at which point you are free to
/// start a new frame.
/// note: ZSTD_e_end will flush as much output as possible, meaning when compressing with multiple threads, it will
/// block until the flush is complete or the output buffer is full.
/// @return : 0 if frame fully completed and fully flushed,
/// >0 if some data still present within internal buffer (the value is minimal estimation of remaining size),
/// or an error code, which can be tested using ZSTD_isError().
typedef ZSTD_CStream = ZSTD_CCtx;

/// ===== Streaming compression functions =====
enum ZSTD_EndDirective {
  /// collect more data, encoder decides when to output compressed result, for optimal compression ratio
  ZSTD_e_continue(0),

  /// flush any data provided so far,
  /// it creates (at least) one new block, that can be decoded immediately on reception;
  /// frame will continue: any future data can still reference previously compressed data, improving compression.
  /// note : multithreaded compression will block to flush as much output as possible.
  ZSTD_e_flush(1),

  /// flush any remaining data _and_ close current frame.
  /// note that frame is only closed after compressed data is fully flushed (return value == 0).
  /// After that point, any additional data starts a new frame.
  /// note : each frame is independent (does not reference any content from previous frame).
  /// : note : multithreaded compression will block to flush as much output as possible.
  ZSTD_e_end(2);

  final int value;
  const ZSTD_EndDirective(this.value);

  static ZSTD_EndDirective fromValue(int value) => switch (value) {
        0 => ZSTD_e_continue,
        1 => ZSTD_e_flush,
        2 => ZSTD_e_end,
        _ => throw ArgumentError('Unknown value for ZSTD_EndDirective: $value'),
      };
}

/// -***************************************************************************
/// Streaming decompression - HowTo
///
/// A ZSTD_DStream object is required to track streaming operations.
/// Use ZSTD_createDStream() and ZSTD_freeDStream() to create/release resources.
/// ZSTD_DStream objects can be re-employed multiple times.
///
/// Use ZSTD_initDStream() to start a new decompression operation.
/// @return : recommended first input size
/// Alternatively, use advanced API to set specific properties.
///
/// Use ZSTD_decompressStream() repetitively to consume your input.
/// The function will update both `pos` fields.
/// If `input.pos < input.size`, some input has not been consumed.
/// It's up to the caller to present again remaining data.
///
/// The function tries to flush all data decoded immediately, respecting output buffer size.
/// If `output.pos < output.size`, decoder has flushed everything it could.
///
/// However, when `output.pos == output.size`, it's more difficult to know.
/// If @return > 0, the frame is not complete, meaning
/// either there is still some data left to flush within internal buffers,
/// or there is more input to read to complete the frame (or both).
/// In which case, call ZSTD_decompressStream() again to flush whatever remains in the buffer.
/// Note : with no additional input provided, amount of data flushed is necessarily <= ZSTD_BLOCKSIZE_MAX.
/// @return : 0 when a frame is completely decoded and fully flushed,
/// or an error code, which can be tested using ZSTD_isError(),
/// or any other value > 0, which means there is still some decoding or flushing to do to complete current frame :
/// the return value is a suggested next input size (just a hint for better latency)
/// that will never request more than the remaining content of the compressed frame.
typedef ZSTD_DStream = ZSTD_DCtx;

final class ZSTD_CDict_s extends ffi.Opaque {}

/// Bulk processing dictionary API
typedef ZSTD_CDict = ZSTD_CDict_s;

final class ZSTD_DDict_s extends ffi.Opaque {}

typedef ZSTD_DDict = ZSTD_DDict_s;

const int ZSTD_VERSION_MAJOR = 1;

const int ZSTD_VERSION_MINOR = 5;

const int ZSTD_VERSION_RELEASE = 8;

const int ZSTD_VERSION_NUMBER = 10508;

const String ZSTD_VERSION_STRING = '1.5.8';

const int ZSTD_CLEVEL_DEFAULT = 3;

const int ZSTD_MAGICNUMBER = 4247762216;

const int ZSTD_MAGIC_DICTIONARY = 3962610743;

const int ZSTD_MAGIC_SKIPPABLE_START = 407710288;

const int ZSTD_MAGIC_SKIPPABLE_MASK = 4294967280;

const int ZSTD_BLOCKSIZELOG_MAX = 17;

const int ZSTD_BLOCKSIZE_MAX = 131072;

const int ZSTD_CONTENTSIZE_UNKNOWN = -1;

const int ZSTD_CONTENTSIZE_ERROR = -2;

const int ZSTD_MAX_INPUT_SIZE = -71777214294589696;
